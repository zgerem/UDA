{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b37cc4e4",
   "metadata": {},
   "source": [
    "# Evaluation of the second model\n",
    "This notebook is for evaluation of the models on cityscapes validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952fc1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from data import CreateTrgDataLoader\n",
    "from PIL import Image\n",
    "import json\n",
    "import os.path as osp\n",
    "import os\n",
    "import numpy as np\n",
    "from model import CreateModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72792f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = [128, 64, 128, 244, 35, 232, 70, 70, 70, 102, 102, 156, 190, 153, 153, 153, 153, 153, 250, 170, 30,\n",
    "           220, 220, 0, 107, 142, 35, 152, 251, 152, 70, 130, 180, 220, 20, 60, 255, 0, 0, 0, 0, 142, 0, 0, 70,\n",
    "           0, 60, 100, 0, 80, 100, 0, 0, 230, 119, 11, 32]\n",
    "zero_pad = 256 * 3 - len(palette)\n",
    "for i in range(zero_pad):\n",
    "    palette.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f96fe",
   "metadata": {},
   "source": [
    "## Test options\n",
    "Adjust the directories to load ground truth labels, model weights and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edda3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "class TestOptions():\n",
    "    def initialize(self):\n",
    "        parser = argparse.ArgumentParser(description=\"test segmentation network\")\n",
    "        parser.add_argument(\"--model\", type=str, default='ENet', help=\"available options : DeepLab,VGG and ENet\")\n",
    "        parser.add_argument(\"--GPU\", type=str, default='0', help=\"which GPU to use\")\n",
    "        parser.add_argument(\"--source\", type=str, default='gta5', help=\"source dataset : gta5 or synthia\")\n",
    "        parser.add_argument(\"--data-dir-target\", type=str, default='../data/cityscapes', help=\"Path to the directory containing the target dataset.\")\n",
    "        parser.add_argument(\"--data-list-target\", type=str, default='./dataset/cityscapes_list/val.txt', help=\"list of images in the target dataset.\")\n",
    "        parser.add_argument(\"--data-dir-test\", type=str, default='../data/GTA5', help=\"Path to the directory containing the source dataset.\")\n",
    "        parser.add_argument(\"--data-list-test\", type=str, default='./dataset/gta5_list/train_all.txt', help=\"Path to the listing of images in the source dataset.\")\n",
    "        parser.add_argument(\"--LB\", type=float, default=0.01, help=\"beta for FDA\")\n",
    "        parser.add_argument(\"--num-classes\", type=int, default=19, help=\"Number of classes for cityscapes.\")\n",
    "        parser.add_argument(\"--set\", type=str, default='val', help=\"choose test set.\")\n",
    "        parser.add_argument(\"--restore-opt1\", type=str, default=None, help=\"restore model parameters from beta1\")\n",
    "        parser.add_argument(\"--restore-opt2\", type=str, default=None, help=\"restore model parameters from beta2\")\n",
    "        parser.add_argument(\"--restore-opt3\", type=str, default=None, help=\"restore model parameters from beta3\")\n",
    "\n",
    "        parser.add_argument(\"--init-weights\", type=str, default=None, help=\"initial model.\")\n",
    "        parser.add_argument(\"--restore-from\", type=str, default='../checkpoints/UDA/step2/gta5_100000', help=\"restore model parameters from\")\n",
    "\n",
    "        parser.add_argument(\"--save\", type=str, default='../results/validation', help=\"Path to save result.\")\n",
    "        parser.add_argument('--gt_dir', type=str, default='../data/cityscapes/gtFine/val', help='directory for CityScapes train gt images')\n",
    "        parser.add_argument('--devkit_dir', type=str, default='./dataset/cityscapes_list', help='list directory of cityscapes')         \n",
    "\n",
    "        return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030690d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "memory_gpu=[int(x.split()[2]) for x in open('tmp','r').readlines()]\n",
    "os.system('rm tmp')    \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(np.argmax(memory_gpu))  \n",
    "\n",
    "\n",
    "if not os.path.exists(args.save):\n",
    "    os.makedirs(args.save)\n",
    "        \n",
    "model = CreateModel(args)   \n",
    "model.eval()\n",
    "model.cuda() \n",
    "\n",
    " \n",
    "targetloader = CreateTrgDataLoader "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1fa4fb",
   "metadata": {},
   "source": [
    "Definitions of the functions to be used for calculation of mIoU and visualization of predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415f2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_mask(mask):\n",
    "    # mask: numpy array of the mask\n",
    "    new_mask = Image.fromarray(mask.astype(np.uint8)).convert('P')\n",
    "    new_mask.putpalette(palette)\n",
    "\n",
    "    return new_mask\n",
    "def fast_hist(a, b, n):\n",
    "    k = (a >= 0) & (a < n)\n",
    "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
    "\n",
    "\n",
    "def per_class_iu(hist):\n",
    "    return np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))\n",
    "\n",
    "\n",
    "def label_mapping(input, mapping):\n",
    "    output = np.copy(input)\n",
    "    for ind in range(len(mapping)):\n",
    "        output[input == mapping[ind][0]] = mapping[ind][1]\n",
    "    return np.array(output, dtype=np.int64)\n",
    "\n",
    "def compute_mIoU(gt_dir, pred_dir, devkit_dir='', restore_from=''):\n",
    "    with open(osp.join(devkit_dir, 'info.json'), 'r') as fp:\n",
    "        info = json.load(fp)\n",
    "    num_classes = np.int(info['classes'])\n",
    "    print('Num classes', num_classes)\n",
    "    name_classes = np.array(info['label'], dtype=np.str)\n",
    "    mapping = np.array(info['label2train'], dtype=np.int)\n",
    "    hist = np.zeros((num_classes, num_classes))\n",
    "\n",
    "    image_path_list = osp.join(devkit_dir, 'val.txt')\n",
    "    label_path_list = osp.join(devkit_dir, 'label.txt')\n",
    "    gt_imgs = open(label_path_list, 'r').read().splitlines()\n",
    "    gt_imgs = [osp.join(gt_dir, x) for x in gt_imgs]\n",
    "    pred_imgs = open(image_path_list, 'r').read().splitlines()\n",
    "    pred_imgs = [osp.join(pred_dir, x.split('/')[-1]) for x in pred_imgs]\n",
    "\n",
    "    for ind in range(len(gt_imgs)):\n",
    "        pred = np.array(Image.open(pred_imgs[ind]))\n",
    "        label = np.array(Image.open(gt_imgs[ind]))\n",
    "        label = label_mapping(label, mapping)\n",
    "        if len(label.flatten()) != len(pred.flatten()):\n",
    "            print('Skipping: len(gt) = {:d}, len(pred) = {:d}, {:s}, {:s}'.format(len(label.flatten()), len(pred.flatten()), gt_imgs[ind], pred_imgs[ind]))\n",
    "            continue\n",
    "        hist += fast_hist(label.flatten(), pred.flatten(), num_classes)\n",
    "        if ind > 0 and ind % 10 == 0:\n",
    "            with open(restore_from+'_mIoU.txt', 'a') as f:\n",
    "                f.write('{:d} / {:d}: {:0.2f}\\n'.format(ind, len(gt_imgs), 100*np.mean(per_class_iu(hist))))\n",
    "            print('{:d} / {:d}: {:0.2f}'.format(ind, len(gt_imgs), 100*np.mean(per_class_iu(hist))))\n",
    "    hist2 = np.zeros((19, 19))\n",
    "    for i in range(19):\n",
    "        hist2[i] = hist[i] / np.sum(hist[i])\n",
    "    \n",
    "    mIoUs = per_class_iu(hist)\n",
    "    for ind_class in range(num_classes):\n",
    "        with open(restore_from+'_mIoU.txt', 'a') as f:\n",
    "            f.write('===>' + name_classes[ind_class] + ':\\t' + str(round(mIoUs[ind_class] * 100, 2)) + '\\n')\n",
    "        print('===>' + name_classes[ind_class] + ':\\t' + str(round(mIoUs[ind_class] * 100, 2)))\n",
    "    with open(restore_from+'_mIoU.txt', 'a') as f:\n",
    "        f.write('===> mIoU: ' + str(round(np.nanmean(mIoUs) * 100, 2)) + '\\n')\n",
    "    print('===> mIoU19: ' + str(round(np.nanmean(mIoUs) * 100, 2)))\n",
    "    print('===> mIoU16: ' + str(round(np.mean(mIoUs[[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 17, 18]]) * 100, 2)))\n",
    "    print('===> mIoU13: ' + str(round(np.mean(mIoUs[[0, 1, 2, 6, 7, 8, 10, 11, 12, 13, 15, 17, 18]]) * 100, 2)))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f24b5",
   "metadata": {},
   "source": [
    "Running this cell will get the predictions from the given model and calculate mIoU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e196b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, batch in enumerate(targetloader):\n",
    "    if index % 100 == 0:\n",
    "        print ('%d processd' % index)\n",
    "    image, _, name = batch\n",
    "    output = model(Variable(image).cuda())\n",
    "    output = nn.functional.softmax(output, dim=1)\n",
    "    output = nn.functional.upsample(output, (1024, 2048), mode='bilinear', align_corners=True).cpu().data[0].numpy()\n",
    "    output = output.transpose(1,2,0)\n",
    "    output_nomask = np.asarray(np.argmax(output, axis=2), dtype=np.uint8)\n",
    "    output_col = colorize_mask(output_nomask)\n",
    "    output_nomask = Image.fromarray(output_nomask)    \n",
    "    name = name[0].split('/')[-1]\n",
    "    output_nomask.save('%s/%s' % (args.save, name))\n",
    "    output_col.save('%s/%s_color.png' % (args.save, name.split('.')[0])) \n",
    "        \n",
    "compute_mIoU(args.gt_dir, args.save, args.devkit_dir, args.restore_from)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
