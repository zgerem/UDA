{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de080fcc",
   "metadata": {},
   "source": [
    "# Training the second model: Step 1\n",
    "After obtaining the pseudo labels from the first model, we train the second model. This time, we do not need grayscale images.\n",
    "This model will be trained with contrastive loss on target data using pseudo labels in addition to cross entropy on source images in target style and entropy minimization on target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cafcd973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.timer import Timer\n",
    "import os\n",
    "from data import CreateSrcDataLoader\n",
    "from data import CreateTrgDataLoaderPseudo\n",
    "from data import CreateTrgDataLoader\n",
    "from model import CreateModel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utils import FDA_source_to_target\n",
    "import scipy.io as sio\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from contrastiveloss import *\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472e56de",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_MEAN = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
    "IMG_MEAN = torch.reshape(torch.from_numpy(IMG_MEAN), (1, 3, 1, 1))\n",
    "\n",
    "CS_weights = np.array((1.0, 1.0, 1.0, 1.0, 100.0, 1.0, 100.0, 100.0, 1.0, 1.0, 1.0,\n",
    "                       100.0, 100.0, 1.0, 1.0, 100.0, 500.0, 500.0, 1000.0), dtype=np.float32)\n",
    "weight_normalizer = CS_weights.max()/2\n",
    "CS_weights = torch.from_numpy(CS_weights/weight_normalizer)\n",
    "# weighting fence, light, sign, person, rider, bus, train, motorcycle, bicycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d1dd9",
   "metadata": {},
   "source": [
    "## Train options\n",
    "Parameters for the training process such as beta, ita, temperature as well as the directories to load/save model weights can be adjusted here. The directory that the weights of this model are saved will be used in the second step for further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddab1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "class TrainOptions():\n",
    "    def initialize(self):\n",
    "        parser = argparse.ArgumentParser( description=\"training script for FDA\" )\n",
    "        parser.add_argument(\"--model\", type=str, default='DeepLab', help=\"available options : DeepLab and VGG\")\n",
    "        parser.add_argument(\"--LB\", type=float, default=0.09, help=\"beta for FDA\")\n",
    "        parser.add_argument(\"--GPU\", type=str, default='0', help=\"which GPU to use\")\n",
    "        parser.add_argument(\"--entW\", type=float, default=0.005, help=\"weight for entropy\")\n",
    "        parser.add_argument(\"--ita\", type=float, default=2.0, help=\"ita for robust entropy\")\n",
    "        parser.add_argument(\"--temperature\", type=float, default=0.07, help=\"temperature for contrastive loss\")\n",
    "        parser.add_argument(\"--switch2entropy\", type=int, default=0, help=\"switch to entropy after this many steps\")\n",
    "        parser.add_argument(\"--switch2contrast\", type=int, default=50000, help=\"switch to contrastive learning  after this many steps\")\n",
    "        parser.add_argument('--threshold', default=0.95, type=float, help='pseudo label threshold')\n",
    "        parser.add_argument(\"--source\", type=str, default='gta5', help=\"source dataset : gta5 or synthia\")\n",
    "        parser.add_argument(\"--target\", type=str, default='cityscapes', help=\"target dataset : cityscapes\")\n",
    "        parser.add_argument(\"--snapshot-dir\", type=str, default='../checkpoints/UDA/step1', help=\"Where to save snapshots of the model.\")\n",
    "        parser.add_argument(\"--data-dir\", type=str, default='../data/GTA5', help=\"Path to the directory containing the source dataset.\")\n",
    "        parser.add_argument(\"--data-list\", type=str, default='./dataset/gta5_list/train_all.txt', help=\"Path to the listing of images in the source dataset.\")\n",
    "        parser.add_argument(\"--data-dir-target\", type=str, default='../data/cityscapes', help=\"Path to the directory containing the target dataset.\")\n",
    "        parser.add_argument(\"--data-list-target\", type=str, default='./dataset/cityscapes_list/train.txt', help=\"list of images in the target dataset.\")\n",
    "        parser.add_argument(\"--data-list-val\", type=str, default='./dataset/cityscapes_list/val.txt', help=\"list of val images in the target dataset.\")\n",
    "        parser.add_argument(\"--set\", type=str, default='train', help=\"choose adaptation set.\")\n",
    "        parser.add_argument(\"--label-folder\", type=str, default=None, help=\"Path to the directory containing the pseudo labels.\")\n",
    "\n",
    "        parser.add_argument(\"--batch-size\", type=int, default=1, help=\"input batch size.\")\n",
    "        parser.add_argument(\"--num-steps\", type=int, default=60000, help=\"Number of training steps.\")\n",
    "        parser.add_argument(\"--num-steps-stop\", type=int, default=100000, help=\"Number of training steps for early stopping.\")\n",
    "        parser.add_argument(\"--num-workers\", type=int, default=4, help=\"number of threads.\")\n",
    "        parser.add_argument(\"--learning-rate\", type=float, default=2.5e-4, help=\"initial learning rate for the segmentation network.\")\n",
    "        parser.add_argument(\"--momentum\", type=float, default=0.9, help=\"Momentum component of the optimiser.\")\n",
    "        parser.add_argument(\"--weight-decay\", type=float, default=0.0005, help=\"Regularisation parameter for L2-loss.\")\n",
    "        parser.add_argument(\"--power\", type=float, default=0.9, help=\"Decay parameter to compute the learning rate (only for deeplab).\")\n",
    "\n",
    "        parser.add_argument(\"--num-classes\", type=int, default=19, help=\"Number of classes for cityscapes.\")\n",
    "        parser.add_argument(\"--init-weights\", type=str, default='../checkpoints/DeepLab_init.pth', help=\"initial model.\")\n",
    "        parser.add_argument(\"--restore-from\", type=str, default=None, help=\"Where restore model parameters from.\")\n",
    "        parser.add_argument(\"--save-pred-every\", type=int, default=1000, help=\"Save summaries and checkpoint every often.\")\n",
    "        parser.add_argument(\"--print-freq\", type=int, default=100, help=\"print loss and time fequency.\")\n",
    "        parser.add_argument(\"--matname\", type=str, default='loss_log.mat', help=\"mat name to save loss\")\n",
    "        parser.add_argument(\"--tempdata\", type=str, default='tempdata.mat', help=\"mat name to save data\")\n",
    "\n",
    "\n",
    "        return parser.parse_args(args=[])\n",
    "    \n",
    "    def print_options(self, args):\n",
    "        message = ''\n",
    "        message += '----------------- Options ---------------\\n'\n",
    "        for k, v in sorted(vars(args).items()):\n",
    "            comment = ''\n",
    "            message += '{:>25}: {:<30}{}\\n'.format(str(k), str(v), comment)\n",
    "        message += '----------------- End -------------------'\n",
    "        print(message)\n",
    "    \n",
    "        # save to the disk\n",
    "        file_name = osp.join(args.snapshot_dir, 'opt.txt')\n",
    "        with open(file_name, 'wt') as args_file:\n",
    "            args_file.write(message)\n",
    "            args_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837b0a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "                      GPU: 0                             \n",
      "                       LB: 0.01                          \n",
      "               batch_size: 1                             \n",
      "                 data_dir: ../data/GTA5                  \n",
      "          data_dir_target: ../data/cityscapes            \n",
      "                data_list: ./dataset/gta5_list/train_all.txt\n",
      "         data_list_target: ./dataset/cityscapes_list/train.txt\n",
      "            data_list_val: ./dataset/cityscapes_list/train.txt\n",
      "                     entW: 0.005                         \n",
      "             init_weights: ../checkpoints/DeepLab_init.pth\n",
      "                      ita: 2.0                           \n",
      "             label_folder: None                          \n",
      "            learning_rate: 0.00025                       \n",
      "                  matname: loss_log.mat                  \n",
      "                    model: DeepLab                       \n",
      "                 momentum: 0.9                           \n",
      "              num_classes: 19                            \n",
      "                num_steps: 100000                        \n",
      "           num_steps_stop: 100000                        \n",
      "              num_workers: 4                             \n",
      "                    power: 0.9                           \n",
      "               print_freq: 100                           \n",
      "             restore_from: None                          \n",
      "          save_pred_every: 1000                          \n",
      "                      set: train                         \n",
      "             snapshot_dir: ../checkpoints/UDA_ENet_val/trained_pseudo_gray_deeplab\n",
      "                   source: gta5                          \n",
      "          switch2contrast: 50000                         \n",
      "           switch2entropy: 0                             \n",
      "                   target: cityscapes                    \n",
      "                 tempdata: tempdata.mat                  \n",
      "              temperature: 0.07                          \n",
      "                threshold: 0.95                          \n",
      "             weight_decay: 0.0005                        \n",
      "----------------- End -------------------\n",
      "model is created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/singh/anaconda3/envs/adl4cv/lib/python3.8/site-packages/torch/optim/sgd.py:69: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(SGD, self).__init__(params, defaults)\n"
     ]
    }
   ],
   "source": [
    "opt = TrainOptions()\n",
    "args = opt.initialize()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.GPU\n",
    "_t = {'iter time': Timer()}\n",
    "\n",
    "model_name = args.source + '_to_' + args.target\n",
    "if not os.path.exists(args.snapshot_dir):\n",
    "    os.makedirs(args.snapshot_dir)\n",
    "    os.makedirs(os.path.join(args.snapshot_dir, 'logs'))\n",
    "opt.print_options(args)\n",
    "\n",
    "\n",
    "sourceloader, targetloader, valloader = CreateSrcDataLoader(args), CreateTrgDataLoaderPseudo(args), CreateValDataLoader(args, True)\n",
    "\n",
    "sourceloader_iter, targetloader_iter, valloader_iter = iter(sourceloader), iter(targetloader), iter(valloader)\n",
    "print(\"model is created\")\n",
    "model, optimizer = CreateModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c036e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_iter = 0\n",
    "if args.restore_from is not None:\n",
    "    start_iter = int(args.restore_from.rsplit('/', 1)[1].rsplit('_')[1])\n",
    "\n",
    "cudnn.enabled = True\n",
    "cudnn.benchmark = True\n",
    "\n",
    "model.train()\n",
    "model.cuda()\n",
    "\n",
    "# losses to log\n",
    "loss_all = 0\n",
    "loss_train = 0\n",
    "loss_val = 0.0\n",
    "loss_contrastive_trg = 0.0\n",
    "loss_ent = 0\n",
    "\n",
    "\n",
    "\n",
    "best_loss_trg = float('inf')\n",
    "loss_val_list = []\n",
    "\n",
    "mean_img = torch.zeros(1, 1)\n",
    "class_weights = Variable(CS_weights).cuda()\n",
    "_t['iter time'].tic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c176eb9",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00368d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/singh/anaconda3/envs/adl4cv/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[it 100][src seg loss 4.2514][trgseg loss 2.5642][contrastive 7.1698][lr 2.4978][195.30s]\n",
      "[it 200][src seg loss 2.2253][trgseg loss 2.0283][contrastive 7.4524][lr 2.4955][182.07s]\n",
      "[it 300][src seg loss 2.6076][trgseg loss 2.1357][contrastive 7.0374][lr 2.4933][181.58s]\n",
      "[it 400][src seg loss 2.4821][trgseg loss 2.3677][contrastive 6.8540][lr 2.4910][179.73s]\n",
      "[it 500][src seg loss 1.4140][trgseg loss 2.0239][contrastive 6.6706][lr 2.4888][182.08s]\n",
      "[it 600][src seg loss 1.4141][trgseg loss 1.6458][contrastive 7.1323][lr 2.4865][180.42s]\n",
      "[it 700][src seg loss 1.1480][trgseg loss 1.1847][contrastive 7.1742][lr 2.4843][180.41s]\n",
      "[it 800][src seg loss 1.5631][trgseg loss 0.9847][contrastive 7.2798][lr 2.4820][181.38s]\n",
      "[it 900][src seg loss 1.5201][trgseg loss 1.1829][contrastive 6.4742][lr 2.4798][179.78s]\n",
      "taking snapshot ...\n",
      "[it 1000][src seg loss 3.4957][trgseg loss 4.7001][contrastive 7.8671][lr 2.4775][180.91s]\n",
      "[it 1100][src seg loss 0.7406][trgseg loss 0.9231][contrastive 8.1684][lr 2.4753][180.33s]\n",
      "[it 1200][src seg loss 0.8128][trgseg loss 1.1188][contrastive 6.6812][lr 2.4730][180.50s]\n",
      "[it 1300][src seg loss 2.0553][trgseg loss 0.7471][contrastive 5.6262][lr 2.4708][180.25s]\n",
      "[it 1400][src seg loss 1.5349][trgseg loss 0.5608][contrastive 6.1507][lr 2.4685][180.38s]\n",
      "[it 1500][src seg loss 0.5829][trgseg loss 0.7489][contrastive 6.4318][lr 2.4662][179.56s]\n",
      "[it 1600][src seg loss 1.4185][trgseg loss 1.5026][contrastive 6.8616][lr 2.4640][180.20s]\n",
      "[it 1700][src seg loss 2.6504][trgseg loss 1.1865][contrastive 5.5129][lr 2.4617][179.70s]\n",
      "[it 1800][src seg loss 1.3641][trgseg loss 1.6646][contrastive 7.4203][lr 2.4595][179.99s]\n",
      "[it 1900][src seg loss 0.8018][trgseg loss 0.7236][contrastive 6.7293][lr 2.4572][180.23s]\n",
      "taking snapshot ...\n",
      "[it 2000][src seg loss 0.8742][trgseg loss 1.0213][contrastive 6.3387][lr 2.4550][181.71s]\n",
      "[it 2100][src seg loss 1.2785][trgseg loss 0.6760][contrastive 5.5082][lr 2.4527][179.57s]\n",
      "[it 2200][src seg loss 1.2254][trgseg loss 0.9447][contrastive 4.9559][lr 2.4505][181.89s]\n",
      "[it 2300][src seg loss 0.5490][trgseg loss 0.7743][contrastive 5.5081][lr 2.4482][180.70s]\n",
      "[it 2400][src seg loss 0.8201][trgseg loss 0.4018][contrastive 5.8505][lr 2.4460][179.48s]\n",
      "[it 2500][src seg loss 0.4529][trgseg loss 1.5912][contrastive 5.9757][lr 2.4437][181.93s]\n",
      "[it 2600][src seg loss 0.4981][trgseg loss 0.7805][contrastive 5.9736][lr 2.4414][181.56s]\n",
      "[it 2700][src seg loss 0.7160][trgseg loss 0.5182][contrastive 5.6779][lr 2.4392][180.02s]\n",
      "[it 2800][src seg loss 1.1789][trgseg loss 3.5022][contrastive 5.8096][lr 2.4369][178.97s]\n",
      "[it 2900][src seg loss 3.2090][trgseg loss 0.8615][contrastive 6.2310][lr 2.4347][179.49s]\n",
      "taking snapshot ...\n",
      "[it 3000][src seg loss 0.8760][trgseg loss 0.7800][contrastive 5.5609][lr 2.4324][180.26s]\n",
      "[it 3100][src seg loss 0.9114][trgseg loss 0.8413][contrastive 5.0247][lr 2.4302][179.55s]\n",
      "[it 3200][src seg loss 1.2849][trgseg loss 0.7877][contrastive 6.3361][lr 2.4279][179.58s]\n",
      "[it 3300][src seg loss 0.6536][trgseg loss 0.5677][contrastive 6.3330][lr 2.4256][180.10s]\n",
      "[it 3400][src seg loss 0.4709][trgseg loss 0.8709][contrastive 5.1433][lr 2.4234][179.63s]\n",
      "[it 3500][src seg loss 0.4798][trgseg loss 0.8999][contrastive 6.0045][lr 2.4211][179.36s]\n",
      "[it 3600][src seg loss 2.8374][trgseg loss 0.8650][contrastive 5.0487][lr 2.4189][179.20s]\n",
      "[it 3700][src seg loss 0.8122][trgseg loss 0.6419][contrastive 5.4282][lr 2.4166][179.36s]\n",
      "[it 3800][src seg loss 0.4009][trgseg loss 0.8646][contrastive 5.0161][lr 2.4144][179.21s]\n",
      "[it 3900][src seg loss 0.4900][trgseg loss 0.5153][contrastive 6.1100][lr 2.4121][179.53s]\n",
      "taking snapshot ...\n",
      "[it 4000][src seg loss 0.2141][trgseg loss 0.5128][contrastive 4.6770][lr 2.4098][180.61s]\n",
      "[it 4100][src seg loss 0.9011][trgseg loss 0.5069][contrastive 5.7190][lr 2.4076][179.59s]\n",
      "[it 4200][src seg loss 0.3370][trgseg loss 0.2859][contrastive 5.3396][lr 2.4053][180.15s]\n",
      "[it 4300][src seg loss 1.3714][trgseg loss 0.9513][contrastive 5.3421][lr 2.4031][179.95s]\n",
      "[it 4400][src seg loss 0.7775][trgseg loss 0.9835][contrastive 4.8556][lr 2.4008][179.20s]\n",
      "[it 4500][src seg loss 0.3511][trgseg loss 0.3215][contrastive 5.1666][lr 2.3985][179.89s]\n",
      "[it 4600][src seg loss 0.5230][trgseg loss 0.5258][contrastive 4.4237][lr 2.3963][180.49s]\n",
      "[it 4700][src seg loss 0.5107][trgseg loss 0.4542][contrastive 3.1131][lr 2.3940][179.58s]\n",
      "[it 4800][src seg loss 0.8505][trgseg loss 0.6365][contrastive 4.1812][lr 2.3918][179.31s]\n",
      "[it 4900][src seg loss 1.0044][trgseg loss 0.3838][contrastive 5.7889][lr 2.3895][179.03s]\n",
      "taking snapshot ...\n",
      "[it 5000][src seg loss 0.5658][trgseg loss 0.7614][contrastive 6.5812][lr 2.3872][180.54s]\n",
      "[it 5100][src seg loss 0.3464][trgseg loss 0.2775][contrastive 5.1431][lr 2.3850][179.99s]\n",
      "[it 5200][src seg loss 0.5713][trgseg loss 0.3078][contrastive 6.4901][lr 2.3827][179.62s]\n",
      "[it 5300][src seg loss 0.7832][trgseg loss 0.3553][contrastive 4.3817][lr 2.3805][180.14s]\n",
      "[it 5400][src seg loss 0.2274][trgseg loss 1.1095][contrastive 5.5648][lr 2.3782][180.08s]\n",
      "[it 5500][src seg loss 0.6721][trgseg loss 0.8908][contrastive 5.1520][lr 2.3759][181.36s]\n",
      "[it 5600][src seg loss 0.8035][trgseg loss 1.0290][contrastive 4.3386][lr 2.3737][179.81s]\n",
      "[it 5700][src seg loss 0.3781][trgseg loss 0.9341][contrastive 5.5131][lr 2.3714][181.00s]\n",
      "[it 5800][src seg loss 0.4516][trgseg loss 0.4058][contrastive 4.4503][lr 2.3691][180.17s]\n",
      "[it 5900][src seg loss 0.4431][trgseg loss 0.3549][contrastive 4.6937][lr 2.3669][179.77s]\n",
      "taking snapshot ...\n",
      "[it 6000][src seg loss 0.2726][trgseg loss 0.8855][contrastive 4.6942][lr 2.3646][180.89s]\n",
      "[it 6100][src seg loss 0.5200][trgseg loss 1.6400][contrastive 5.0764][lr 2.3623][180.05s]\n",
      "[it 6200][src seg loss 0.3770][trgseg loss 1.0184][contrastive 5.2646][lr 2.3601][179.92s]\n",
      "[it 6300][src seg loss 0.3591][trgseg loss 0.7949][contrastive 4.8296][lr 2.3578][179.67s]\n",
      "[it 6400][src seg loss 1.1557][trgseg loss 0.3342][contrastive 4.5588][lr 2.3556][179.77s]\n",
      "[it 6500][src seg loss 0.2853][trgseg loss 0.2266][contrastive 5.0244][lr 2.3533][180.39s]\n",
      "[it 6600][src seg loss 0.2271][trgseg loss 0.4502][contrastive 4.6779][lr 2.3510][181.19s]\n",
      "[it 6700][src seg loss 0.3553][trgseg loss 0.2902][contrastive 5.1730][lr 2.3488][180.23s]\n",
      "[it 6800][src seg loss 0.9006][trgseg loss 0.5309][contrastive 5.8901][lr 2.3465][180.30s]\n",
      "[it 6900][src seg loss 1.2142][trgseg loss 0.3698][contrastive 6.0081][lr 2.3442][180.05s]\n",
      "taking snapshot ...\n",
      "[it 7000][src seg loss 0.5047][trgseg loss 1.2325][contrastive 4.8379][lr 2.3420][180.80s]\n",
      "[it 7100][src seg loss 0.6371][trgseg loss 1.0626][contrastive 5.0465][lr 2.3397][180.37s]\n",
      "[it 7200][src seg loss 0.4789][trgseg loss 0.8193][contrastive 7.4475][lr 2.3374][180.81s]\n",
      "[it 7300][src seg loss 0.4750][trgseg loss 0.7173][contrastive 4.4403][lr 2.3352][179.95s]\n",
      "[it 7400][src seg loss 0.7471][trgseg loss 0.4422][contrastive 4.0257][lr 2.3329][179.58s]\n",
      "[it 7500][src seg loss 0.5040][trgseg loss 0.3290][contrastive 5.6180][lr 2.3306][180.65s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(start_iter, args.num_steps):\n",
    "    model.adjust_learning_rate(args, optimizer, i)  # adjust learning rate\n",
    "    optimizer.zero_grad()  # zero grad\n",
    "    \n",
    "    src_img, src_lbl, _, _ = sourceloader_iter.next()  # new batch source\n",
    "    trg_img, trg_lbl, trg_lbl_pseudo, _, _ = targetloader_iter.next()  # new batch target\n",
    "    \n",
    "    if mean_img.shape[-1] < 2:\n",
    "        B, C, H, W = trg_img.shape\n",
    "        mean_img = IMG_MEAN.repeat(B, 1, H, W)\n",
    "\n",
    "\n",
    "\n",
    "    # 1. perform spectral transfer on source to get image in target style\n",
    "    src_in_trg = FDA_source_to_target(src_img, trg_img, L=args.LB)  # src_lbl\n",
    "    src_in_trg = src_in_trg - mean_img  # trg_img \n",
    "    \n",
    "    \n",
    "    # 2. forward pass source image in trg \n",
    "    src_in_trg, src_lbl = Variable(src_in_trg).cuda(), Variable(src_lbl.long()).cuda()  # to gpu\n",
    "    src_seg_score = model(src_in_trg, lbl=src_lbl, weight=class_weights, ita=args.ita)  # forward pass\n",
    "    loss_seg_src = model.loss_seg  # get loss\n",
    "\n",
    "    # 3. perform spectral transfer on target to get image in source style\n",
    "    trg_in_src = FDA_source_to_target(trg_img, src_img, L=args.LB)  # src_lbl\n",
    "    trg_in_src = trg_in_src - mean_img  # trg_img \n",
    "    \n",
    "    # 4. forward pass target image in source style\n",
    "    trg_in_src, trg_lbl_pseudo = Variable(trg_in_src).cuda(), Variable(trg_lbl_pseudo.long()).cuda()  # to gpu\n",
    "    trg_seg_score = model(trg_in_src, lbl=trg_lbl, weight=class_weights, ita=args.ita)  # forward pass\n",
    "    trg_in_src_cont = model.cont # get the embeddings to compute contrastive loss\n",
    "    \n",
    "    # 5. forward pass target image\n",
    "    trg_img, trg_lbl = Variable(trg_img).cuda(), Variable(trg_lbl.long()).cuda()  # to gpu\n",
    "    trg_seg_score = model(trg_img, lbl=trg_lbl, weight=class_weights, ita=args.ita)  # forward pass\n",
    "    loss_seg_trg = model.loss_seg  # get loss\n",
    "    loss_ent_trg = model.loss_ent\n",
    "    trg_cont = model.cont # get the embeddings to compute contrastive loss\n",
    "    \n",
    "    # 6. sum all the losses and backpropagate \n",
    "    loss_all = loss_seg_src + int(i>=args.switch2contrast)*loss_cont_trg + int(i>=args.switch2contrast)*args.entW*loss_ent_trg\n",
    "    loss_all.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    # save the model weights for each save_pred_every steps\n",
    "    if (i + 1) % args.save_pred_every == 0:\n",
    "        print('taking snapshot ...')\n",
    "        torch.save(model.state_dict(), os.path.join(args.snapshot_dir, '%s_' % (args.source) + str(i + 1) + '.pth'))\n",
    "       \n",
    "    if (i + 1) % args.print_freq == 0:\n",
    "        _t['iter time'].toc(average=False)\n",
    "        print('[it %d][src seg loss %.4f][lr %.4f][%.2fs]' % \\\n",
    "              (i + 1,loss_seg_src.data, optimizer.param_groups[0]['lr'] * 10000,\n",
    "               _t['iter time'].diff))\n",
    "    \n",
    "        sio.savemat(args.tempdata, {'trg_img': trg_img.cpu().numpy()})\n",
    "        \n",
    "        loss_train /= args.print_freq\n",
    "        \n",
    "        \n",
    "        \n",
    "        writer.add_scalar('Training loss', loss_train, i)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss_train = 0.0\n",
    "    \n",
    "        \n",
    "        if i + 1 > args.num_steps_stop:\n",
    "            print('finish training')\n",
    "            break\n",
    "        _t['iter time'].tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137fcb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
