{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a703fd53",
   "metadata": {},
   "source": [
    "# Training for pseudo labels\n",
    "As the first part of the overall training, we train a DeepLabV2 model and get pseudo labels. In this notebook, the model will be trained with grayscale source and target images.\n",
    "Cross entropy loss is used for training on grayscale source images. For grayscale target images, entropy minimization is performed. \n",
    "To load images in grayscale format, we will use datagray as dataloader instead of data as in the other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb417f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.timer import Timer\n",
    "import os\n",
    "from datagray import CreateSrcDataLoader\n",
    "from datagray import CreateTrgDataLoader\n",
    "from model import CreateModel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utils import FDA_source_to_target\n",
    "import scipy.io as sio\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd0ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_MEAN = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
    "IMG_MEAN = torch.reshape(torch.from_numpy(IMG_MEAN), (1, 3, 1, 1))\n",
    "\n",
    "# weighting fence, light, sign, person, rider, bus, train, motorcycle, bicycle\n",
    "CS_weights = np.array((1.0, 1.0, 1.0, 1.0, 100.0, 1.0, 100.0, 100.0, 1.0, 1.0, 1.0,\n",
    "                       100.0, 100.0, 1.0, 1.0, 100.0, 500.0, 500.0, 1000.0), dtype=np.float32)\n",
    "weight_normalizer = CS_weights.max()/2\n",
    "CS_weights = torch.from_numpy(CS_weights/weight_normalizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b2800e",
   "metadata": {},
   "source": [
    "## Train options\n",
    "Parameters for the training process such as beta, ita, temperature as well as the directories to load/save model weights can be adjusted here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b9af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "class TrainOptions():\n",
    "    def initialize(self):\n",
    "        parser = argparse.ArgumentParser( description=\"training script for FDA\" )\n",
    "        parser.add_argument(\"--model\", type=str, default='DeepLab', help=\"available options : DeepLab and VGG\")\n",
    "        parser.add_argument(\"--LB\", type=float, default=0.1, help=\"beta for FDA\")\n",
    "        parser.add_argument(\"--GPU\", type=str, default='0', help=\"which GPU to use\")\n",
    "        parser.add_argument(\"--entW\", type=float, default=0.005, help=\"weight for entropy\")\n",
    "        parser.add_argument(\"--ita\", type=float, default=2.0, help=\"ita for robust entropy\")\n",
    "        parser.add_argument(\"--temperature\", type=float, default=0.07, help=\"temperature for contrastive loss\")\n",
    "        parser.add_argument(\"--switch2entropy\", type=int, default=0, help=\"switch to entropy after this many steps\")\n",
    "        parser.add_argument(\"--switch2contrast\", type=int, default=0, help=\"switch to contrastive learning  after this many steps\")\n",
    "        parser.add_argument('--threshold', default=0.95, type=float, help='pseudo label threshold')\n",
    "        parser.add_argument(\"--source\", type=str, default='gta5', help=\"source dataset : gta5 or synthia\")\n",
    "        parser.add_argument(\"--target\", type=str, default='cityscapes', help=\"target dataset : cityscapes\")\n",
    "        parser.add_argument(\"--snapshot-dir\", type=str, default='../checkpoints/UDA/model1', help=\"Where to save snapshots of the model.\")\n",
    "        parser.add_argument(\"--data-dir\", type=str, default='../data/GTA5', help=\"Path to the directory containing the source dataset.\")\n",
    "        parser.add_argument(\"--data-list\", type=str, default='./dataset/gta5_list/train_all.txt', help=\"Path to the listing of images in the source dataset.\")\n",
    "        parser.add_argument(\"--data-dir-target\", type=str, default='../data/cityscapes', help=\"Path to the directory containing the target dataset.\")\n",
    "        parser.add_argument(\"--data-list-target\", type=str, default='./dataset/cityscapes_list/train.txt', help=\"list of images in the target dataset.\")\n",
    "        parser.add_argument(\"--set\", type=str, default='train', help=\"choose adaptation set.\")\n",
    "        parser.add_argument(\"--label-folder\", type=str, default=None, help=\"Path to the directory containing the pseudo labels.\")\n",
    "\n",
    "        parser.add_argument(\"--batch-size\", type=int, default=1, help=\"input batch size.\")\n",
    "        parser.add_argument(\"--num-steps\", type=int, default=100000, help=\"Number of training steps.\")\n",
    "        parser.add_argument(\"--num-steps-stop\", type=int, default=100000, help=\"Number of training steps for early stopping.\")\n",
    "        parser.add_argument(\"--num-workers\", type=int, default=4, help=\"number of threads.\")\n",
    "        parser.add_argument(\"--learning-rate\", type=float, default=2.5e-4, help=\"initial learning rate for the segmentation network.\")\n",
    "        parser.add_argument(\"--momentum\", type=float, default=0.9, help=\"Momentum component of the optimiser.\")\n",
    "        parser.add_argument(\"--weight-decay\", type=float, default=0.0005, help=\"Regularisation parameter for L2-loss.\")\n",
    "        parser.add_argument(\"--power\", type=float, default=0.9, help=\"Decay parameter to compute the learning rate (only for deeplab).\")\n",
    "\n",
    "        parser.add_argument(\"--num-classes\", type=int, default=19, help=\"Number of classes for cityscapes.\")\n",
    "        parser.add_argument(\"--init-weights\", type=str, default='../checkpoints/DeepLab_init.pth', help=\"initial model.\")\n",
    "        parser.add_argument(\"--restore-from\", type=str, default=None, help=\"Where restore model parameters from.\")\n",
    "        parser.add_argument(\"--save-pred-every\", type=int, default=1000, help=\"Save summaries and checkpoint every often.\")\n",
    "        parser.add_argument(\"--print-freq\", type=int, default=100, help=\"print loss and time fequency.\")\n",
    "        parser.add_argument(\"--matname\", type=str, default='loss_log.mat', help=\"mat name to save loss\")\n",
    "        parser.add_argument(\"--tempdata\", type=str, default='tempdata.mat', help=\"mat name to save data\")\n",
    "\n",
    "\n",
    "        return parser.parse_args(args=[])\n",
    "    \n",
    "    def print_options(self, args):\n",
    "        message = ''\n",
    "        message += '----------------- Options ---------------\\n'\n",
    "        for k, v in sorted(vars(args).items()):\n",
    "            comment = ''\n",
    "            message += '{:>25}: {:<30}{}\\n'.format(str(k), str(v), comment)\n",
    "        message += '----------------- End -------------------'\n",
    "        print(message)\n",
    "    \n",
    "        # save to the disk\n",
    "        file_name = osp.join(args.snapshot_dir, 'opt.txt')\n",
    "        with open(file_name, 'wt') as args_file:\n",
    "            args_file.write(message)\n",
    "            args_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0007ca82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "                      GPU: 0                             \n",
      "                       LB: 0.1                           \n",
      "               batch_size: 1                             \n",
      "                 data_dir: ../data/GTA5                  \n",
      "          data_dir_target: ../data/cityscapes            \n",
      "                data_list: ./dataset/gta5_list/train_all.txt\n",
      "         data_list_target: ./dataset/cityscapes_list/train.txt\n",
      "                     entW: 0.005                         \n",
      "             init_weights: ../checkpoints/DeepLab_init.pth\n",
      "                      ita: 2.0                           \n",
      "             label_folder: None                          \n",
      "            learning_rate: 0.00025                       \n",
      "                  matname: loss_log.mat                  \n",
      "                    model: DeepLab                       \n",
      "                 momentum: 0.9                           \n",
      "              num_classes: 19                            \n",
      "                num_steps: 100000                        \n",
      "           num_steps_stop: 100000                        \n",
      "              num_workers: 4                             \n",
      "                    power: 0.9                           \n",
      "               print_freq: 100                           \n",
      "             restore_from: None                          \n",
      "          save_pred_every: 1000                          \n",
      "                      set: train                         \n",
      "             snapshot_dir: ../checkpoints/UDA/model1     \n",
      "                   source: gta5                          \n",
      "          switch2contrast: 0                             \n",
      "           switch2entropy: 0                             \n",
      "                   target: cityscapes                    \n",
      "                 tempdata: tempdata.mat                  \n",
      "              temperature: 0.07                          \n",
      "                threshold: 0.95                          \n",
      "             weight_decay: 0.0005                        \n",
      "----------------- End -------------------\n",
      "model is created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/singh/anaconda3/envs/adl4cv/lib/python3.8/site-packages/torch/optim/sgd.py:69: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(SGD, self).__init__(params, defaults)\n"
     ]
    }
   ],
   "source": [
    "opt = TrainOptions()\n",
    "args = opt.initialize()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.GPU\n",
    "_t = {'iter time': Timer()}\n",
    "\n",
    "model_name = args.source + '_to_' + args.target\n",
    "if not os.path.exists(args.snapshot_dir):\n",
    "    os.makedirs(args.snapshot_dir)\n",
    "    os.makedirs(os.path.join(args.snapshot_dir, 'logs'))\n",
    "opt.print_options(args)\n",
    "\n",
    "sourceloader, targetloader = CreateSrcDataLoader(args), CreateTrgDataLoader(args)\n",
    "sourceloader_iter, targetloader_iter = iter(sourceloader), iter(targetloader)\n",
    "print(\"model is created\")\n",
    "model, optimizer = CreateModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53280777",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_iter = 0\n",
    "\n",
    "# if the model is restored, get the last iterations as start_iter\n",
    "if args.restore_from is not None:\n",
    "    start_iter = int(args.restore_from.rsplit('/', 1)[1].rsplit('_')[1])\n",
    "\n",
    "cudnn.enabled = True\n",
    "cudnn.benchmark = True\n",
    "\n",
    "model.train()\n",
    "model.cuda()\n",
    "\n",
    "# losses to log\n",
    "loss_all = 0\n",
    "loss_train = 0\n",
    "loss_val = 0.0\n",
    "loss_ent = 0\n",
    "\n",
    "best_loss_trg = float('inf')\n",
    "loss_val_list = []\n",
    "\n",
    "mean_img = torch.zeros(1, 1)\n",
    "class_weights = Variable(CS_weights).cuda()\n",
    "_t['iter time'].tic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed4a76",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b238f168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/singh/anaconda3/envs/adl4cv/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[it 100][src seg loss 2.8874][trg seg loss 4.5537][lr 2.4978][109.82s]\n",
      "[it 200][src seg loss 1.5248][trg seg loss 3.2787][lr 2.4955][105.94s]\n",
      "[it 300][src seg loss 1.8459][trg seg loss 2.1203][lr 2.4933][107.19s]\n",
      "[it 400][src seg loss 1.3691][trg seg loss 4.2199][lr 2.4910][106.26s]\n",
      "[it 500][src seg loss 1.3471][trg seg loss 4.4983][lr 2.4888][105.20s]\n",
      "[it 600][src seg loss 0.8436][trg seg loss 2.0812][lr 2.4865][104.98s]\n",
      "[it 700][src seg loss 0.7600][trg seg loss 5.2852][lr 2.4843][105.01s]\n",
      "[it 800][src seg loss 1.9242][trg seg loss 5.1813][lr 2.4820][106.95s]\n",
      "[it 900][src seg loss 1.0364][trg seg loss 1.3531][lr 2.4798][105.37s]\n",
      "taking snapshot ...\n",
      "[it 1000][src seg loss 1.0378][trg seg loss 2.0518][lr 2.4775][106.02s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(start_iter, 30000):\n",
    "    model.adjust_learning_rate(args, optimizer, i)  # adjust learning rate\n",
    "    optimizer.zero_grad()  # zero grad\n",
    "    \n",
    "    src_img, src_lbl, _, _ = sourceloader_iter.next()  # new batch source\n",
    "    trg_img, trg_lbl, _, _ = targetloader_iter.next()  # new batch target\n",
    "    \n",
    "    if mean_img.shape[-1] < 2:\n",
    "        B, C, H, W = trg_img.shape\n",
    "        mean_img = IMG_MEAN.repeat(B, 1, H, W)\n",
    "\n",
    "\n",
    "    \n",
    "    # 1. forward pass source image \n",
    "    src_img = src_img - mean_img\n",
    "    src_img, src_lbl = Variable(src_img).cuda(), Variable(src_lbl.long()).cuda()  # to gpu\n",
    "    src_seg_score = model(src_img, lbl=src_lbl, weight=class_weights, ita=args.ita)  # forward pass\n",
    "    loss_seg_src = model.loss_seg  # get segmentation loss\n",
    "\n",
    "    # 2. forward pass target image \n",
    "    trg_img, trg_lbl = Variable(trg_img).cuda(), Variable(trg_lbl.long()).cuda()  # to gpu\n",
    "    trg_seg_score = model(trg_img, lbl=trg_lbl, weight=class_weights, ita=args.ita)  # forward pass\n",
    "    loss_seg_trg = model.loss_seg  # get segmentation loss\n",
    "    loss_ent_trg = model.loss_ent # get entropy \n",
    "    \n",
    "    # sum segmentation loss on source data and entropy on target data to backpropagate \n",
    "    loss_all = loss_seg_src + args.entW*loss_ent_trg\n",
    "    loss_all.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "    loss_train += loss_seg_src.detach().cpu().numpy()\n",
    "    loss_val += loss_seg_trg.detach().cpu().numpy()\n",
    "    loss_ent += loss_ent_trg.detach().cpu().numpy()\n",
    "    \n",
    "    # save the model weights for each save_pred_every steps\n",
    "    if (i + 1) % args.save_pred_every == 0:\n",
    "        print('taking snapshot ...')\n",
    "        torch.save(model.state_dict(), os.path.join(args.snapshot_dir, '%s_' % (args.source) + str(i + 1) + '.pth'))\n",
    "        \n",
    "    # save the model with smallest validation loss as the best model\n",
    "    if best_loss_trg > loss_seg_trg:\n",
    "        best_loss_trg = loss_seg_trg\n",
    "        torch.save(model.state_dict(), os.path.join(args.snapshot_dir, '%s_' % (args.source) +'best'+ '.pth'))\n",
    "    \n",
    "    if (i + 1) % args.print_freq == 0:\n",
    "        _t['iter time'].toc(average=False)\n",
    "        print('[it %d][src seg loss %.4f][trg seg loss %.4f][lr %.4f][%.2fs]' % \\\n",
    "              (i + 1,loss_seg_src.data, loss_seg_trg.data, optimizer.param_groups[0]['lr'] * 10000,\n",
    "               _t['iter time'].diff))\n",
    "    \n",
    "        sio.savemat(args.tempdata, {'trg_img': trg_img.cpu().numpy()})\n",
    "        \n",
    "        loss_train /= args.print_freq\n",
    "        loss_val /= args.print_freq\n",
    "        loss_val_list.append(loss_val)\n",
    "        loss_ent /= args.print_freq\n",
    "        \n",
    "        writer.add_scalar('Training loss', loss_train, i)\n",
    "        writer.add_scalar('Validation loss', loss_val, i )\n",
    "        writer.add_scalar('Entropy loss', loss_ent, i)\n",
    "        \n",
    "        sio.savemat(args.matname, {'loss_val': loss_val_list})\n",
    "        loss_train = 0.0\n",
    "        loss_val = 0.0\n",
    "        loss_ent = 0.0\n",
    "        \n",
    "        if i + 1 > args.num_steps_stop:\n",
    "            print('finish training')\n",
    "            break\n",
    "        _t['iter time'].tic()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
